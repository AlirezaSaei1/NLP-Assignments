{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-Filler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "from hazm import sent_tokenize, word_tokenize, Normalizer\n",
    "import nltk\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>نسبت به قیمتش ارزش خرید داره\\nجاداره، طراحیش ق...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چند ماهی میشه که گرفتمش‌. برای برنامه نویسی و ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>پراید ستون جدید</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>اقا همه چیش خوبه فقط از پایین زیاد حاشیه داره ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>گوسی هو اوی p10 lite سیپیو و دوربین و رمش از ا...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment\n",
       "0  نسبت به قیمتش ارزش خرید داره\\nجاداره، طراحیش ق...\n",
       "1  چند ماهی میشه که گرفتمش‌. برای برنامه نویسی و ...\n",
       "2                                    پراید ستون جدید\n",
       "3  اقا همه چیش خوبه فقط از پایین زیاد حاشیه داره ...\n",
       "4  گوسی هو اوی p10 lite سیپیو و دوربین و رمش از ا..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = pd.read_csv('Datasets\\digikala_comment.csv')\n",
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentenes(sentences_DataFrame):\n",
    "    # Convert comments into sentences\n",
    "    normalizer = Normalizer()\n",
    "    comments_df['sentences'] = comments_df['comment'].apply(lambda comment: sent_tokenize(comment))\n",
    "    comments_df.drop('comment', axis=1, inplace=True)\n",
    "\n",
    "    # Convert DataFrame into a list of sentences\n",
    "    sentences_list = comments_df['sentences'].tolist()\n",
    "    flat_sentences_list = [sentence for sublist in sentences_list for sentence in sublist]\n",
    "\n",
    "    normalized_sentences = [normalizer.normalize(s) for s in flat_sentences_list]\n",
    "\n",
    "    # Remove Zero-Width Non-Joiners\n",
    "    sentences = [sentence.replace('\\u200c', ' ') for sentence in normalized_sentences]\n",
    "\n",
    "    # Remove punctuations from sentences\n",
    "    punctuations = string.punctuation + '،' + '؟'\n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        cleaned_sentence = ''.join(char for char in sentence if char not in punctuations)\n",
    "        cleaned_sentences.append(cleaned_sentence)\n",
    "\n",
    "    return cleaned_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_sentenes = preprocess_sentenes(comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نسبت به قیمتش ارزش خرید داره جاداره طراحیش قشنگه تنها مشکلش بندهای ضعیفش هست که باعث میشه استحکام چندانی نداشنه باشه\n",
      "چند ماهی میشه که گرفتمش\n",
      "برای برنامه نویسی و کارای گرافیکی ازش استفاده می کنم\n",
      "واقعا از هر لحاظ بگین عالیه\n",
      "پراید ستون جدید\n",
      "اقا همه چیش خوبه فقط از پایین زیاد حاشیه داره که با روشن شدن گوشی بیشتر هم میشه\n",
      "و نکته دیگه اینکه به خاطر این که اطرافش یه کوچلو خمیده هست گلس بعد یه مدتی جدا مشیه\n",
      "ولی در کل با این قیمت بهترین گوشی هست و همه چی داره از دوربین گرفته تا رم و سی پی یو و گرافیک و حسگر های مختلف و خیلی چیزای دیگه\n",
      "گوسی هو اوی p ۱۰ lite سیپیو و دوربین و رمش از این خیلی بهتره خودتون میتونین برین تمام مقایسه های p ۱۰ liteو این گوشیو ببینین\n",
      "چادر سبک و زیباییه دوختشم عالیه\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(preprocessed_sentenes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ngrams(sentences):\n",
    "    # Tokenize sentences into words\n",
    "    tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "    \n",
    "    unigrams = [word for sentence in tokenized_sentences for word in sentence]\n",
    "    bigrams_list = list(bigrams(unigrams))\n",
    "    trigrams_list = list(trigrams(unigrams))\n",
    "    \n",
    "    return unigrams, bigrams_list, trigrams_list\n",
    "\n",
    "def count_ngrams(unigrams, bigrams_list, trigrams_list):\n",
    "    unigram_counts = Counter(unigrams)\n",
    "    bigram_counts = Counter(bigrams_list)\n",
    "    trigram_counts = Counter(trigrams_list)\n",
    "    \n",
    "    return unigram_counts, bigram_counts, trigram_counts\n",
    "\n",
    "def report_most_frequent_ngrams(unigram_counts, bigram_counts, trigram_counts):\n",
    "    print(\"Most frequent unigrams:\")\n",
    "    for word, count in unigram_counts.most_common(8):\n",
    "        print(f\"{word}: {count}\")\n",
    "\n",
    "    print(\"\\nMost frequent bigrams:\")\n",
    "    for bigram, count in bigram_counts.most_common(8):\n",
    "        print(f\"{' '.join(bigram)}: {count}\")\n",
    "\n",
    "    print(\"\\nMost frequent trigrams:\")\n",
    "    for trigram, count in trigram_counts.most_common(8):\n",
    "        print(f\"{' '.join(trigram)}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent unigrams:\n",
      "و: 370\n",
      "از: 215\n",
      "که: 187\n",
      "این: 164\n",
      "به: 156\n",
      "هم: 123\n",
      "خیلی: 112\n",
      "رو: 108\n",
      "\n",
      "Most frequent bigrams:\n",
      "می کنم: 28\n",
      "نسبت به: 23\n",
      "از این: 19\n",
      "این گوشی: 18\n",
      "در کل: 17\n",
      "پیشنهاد می: 15\n",
      "دیجی کالا: 15\n",
      "بعد از: 14\n",
      "\n",
      "Most frequent trigrams:\n",
      "پیشنهاد می کنم: 15\n",
      "نسبت به قیمتش: 9\n",
      "ممنون از دیجی: 9\n",
      "حتما پیشنهاد می: 8\n",
      "از دیجی کالا: 8\n",
      "به نظر من: 7\n",
      "این گوشی رو: 6\n",
      "می کنم ممنون: 6\n"
     ]
    }
   ],
   "source": [
    "unigrams, bigrams, trigrams = extract_ngrams(preprocessed_sentenes)\n",
    "uc, bc, tc = count_ngrams(unigrams, bigrams, trigrams)\n",
    "report_most_frequent_ngrams(uc, bc, tc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
